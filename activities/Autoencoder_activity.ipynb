{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "Today we will use `keras` in `tensorflow` to build an autoencoder. We will use a simple neural network architecture that is composed of an input layer a lower-dimensional latent space, and an output layer of equal size.\n",
    "\n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-06-at-3.17.13-PM.png\" width=\"400\" />\n",
    "\n",
    "Autoencoders are an *unsupervised learning* method. We will use an autoencoder to create a latent space representation of the `digits` dataset, a reduced-dimension version of the `MNIST` dataset. Replacing the `digits` dataset with the larger `MNIST` dataset is perhaps a more useful activity, but increases the runtime of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages used in notebook!\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, cluster # for k-means clustering\n",
    "import random # if we want to create a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The digits dataset, made of already small 8x8 pixel images of digits 0-9\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# let's have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset. \n",
    "\n",
    "# let's keep labels in case we want them later\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "data = data/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "# print the number of features and the number of training examples\n",
    "print(len(data[0]))\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we build the autoencoder. Ours is a standard feed-forward neural network architecture with three layers as descibed above.\n",
    "\n",
    "Let's start by reducing our dimensionality by a factor of two and see if we can recover our original images.\n",
    "\n",
    "One way to build an autoencoder is to store each layer into a variable so that we can access the different pieces later. \n",
    "\n",
    "*Note: I achieved my best performance with a `relu` activation function. On both the encoded and output layers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 32\n",
    "\n",
    "# define your Input layer\n",
    "\n",
    "# define your encoded layer\n",
    "\n",
    "# define your output layer\n",
    "\n",
    "\n",
    "# put the layer together to create your Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the autoencoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have out autencoder model, let's also use the layers we already made to construct an **encoder** and **decoder** model, so we can use each piece separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build encoder and decoder models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce predictions from your trained model\n",
    "#encoded_imgs = \n",
    "#decoded_imgs = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at some images that our autoencoder produced\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *If there is time*:\n",
    "### We can then try k-means clustering on the latent space to see if we can separate numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn's KMeans to cluster on the autoencoder's latent space:\n",
    "#y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a subset of examples and their cluster assignment\n",
    "for i in range(25):\n",
    "    fig = plt.subplot(5, 5, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(data[i].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('y_pred: %i' % y_pred[i])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at cluster 1\n",
    "for i in range(len(data)):\n",
    "    if y_pred[i] == 1:\n",
    "        plt.imshow(data[i].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('y_pred: %i' % y_pred[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at cluster 2\n",
    "for i in range(len(data)):)\n",
    "    if y_pred[i] == 2:\n",
    "        plt.imshow(data[i].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('y_pred: %i' % y_pred[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try to use your trained decoder as a number generator! You provide the decoder with a latent space input that is of similar values to the ones you got in training. So many fun things to try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as `lastname1_lastname2_autoencoder.ipynb` and submit on Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
